{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2119948,"sourceType":"datasetVersion","datasetId":1272055}],"dockerImageVersionId":30407,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/fahmikazimd/ml-project-bn-to-en-transformer-model?scriptVersionId=172010617\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Imports**","metadata":{"editable":false}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport timm\nimport torch.optim as optim\n\nfrom transformers import DistilBertModel, DistilBertConfig, DistilBertTokenizer\nfrom transformers import AutoTokenizer, AutoModel\n\nimport math\nimport numpy as np","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Config**","metadata":{"editable":false}},{"cell_type":"code","source":"class Config:\n    tokeniserModel = \"bert-base-multilingual-cased\"\n    vocabSize = 119547\n    maxLength = 1024\n    dModel = 768\n    numHeads = 3\n    numLayers = 6\n    dropout = 0.1\n    learningRate = 1e-3\n    batchSize = 8\n    epochs = 100\n    ","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Loading Dataset**","metadata":{"editable":false}},{"cell_type":"code","source":"basDir= \"/kaggle/input/samanantar/final_data/en-bn/\"\nEN_PATH = basDir + \"train.en\"\nBN_PATH = basDir + \"train.bn\"","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"EN_PATH:\", EN_PATH)\n# print(\"BN_PATH\", BN_PATH)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, EN_PATH, BN_PATH):\n        self.targetPath = EN_PATH\n        self.sourcePath = BN_PATH\n        self.tokenizer = AutoTokenizer.from_pretrained(Config.tokeniserModel)\n        with open(self.sourcePath, mode='rt', encoding='utf-8') as file:\n            self.source = file.read().strip().split('\\n')\n            \n        with open(self.targetPath, mode='rt', encoding='utf-8') as file:\n            self.target = file.read().strip().split('\\n')\n        print(\"Data read successfully\")\n            \n    def __getitem__(self, index):\n        src = tokenizer(self.source[index], padding=\"max_length\", max_length=Config.maxLength, return_tensors=\"pt\").to(device)\n        tgt = tokenizer(self.target[index], padding=\"max_length\", max_length=Config.maxLength, return_tensors=\"pt\").to(device)\n        src = src[\"input_ids\"]\n        tgt = tgt[\"input_ids\"]\n        return tgt, src\n    \n    def __len__(self):\n        return len(self.source)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = Dataset(EN_PATH, BN_PATH)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finding vocab size","metadata":{"editable":false}},{"cell_type":"code","source":"VAL_SIZE = TEST_SIZE = (len(dataset) * 15) // 100\nTRAIN_SIZE = len(dataset) - (VAL_SIZE + TEST_SIZE)\nprint(\"TRAIN_SIZE:\", TRAIN_SIZE,\",VAL_SIZE:\", VAL_SIZE,\",TEST_SIZE:\", TEST_SIZE)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainSet, valSet, testSet = torch.utils.data.random_split(dataset, [TRAIN_SIZE, VAL_SIZE, TEST_SIZE])","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=Config.batchSize, shuffle=2)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validationLoader = torch.utils.data.DataLoader(valSet, batch_size=Config.batchSize, shuffle=2)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testLoader = torch.utils.data.DataLoader(testSet, batch_size=Config.batchSize, shuffle=2)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Implementation**","metadata":{"editable":false}},{"cell_type":"markdown","source":"# Positional Encoder","metadata":{"editable":false}},{"cell_type":"code","source":"class PositionalEncoder(nn.Module):\n    def __init__(self, d_model, max_seq_len):\n        super(PositionalEncoder, self).__init__()\n        self.d_model = d_model\n        self.max_seq_len = max_seq_len\n        \n        # Compute the positional encodings once in the constructor\n        pe = torch.zeros(max_seq_len, d_model)\n        position = torch.arange(0, max_seq_len, dtype=torch.float32).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        # Add the positional encodings to the input tensor\n        x = x + self.pe[:, :x.size(1)]\n        return x\n","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Masked Multihead Attention","metadata":{"editable":false}},{"cell_type":"code","source":"class MaskedMultiheadAttention(nn.Module):\n    def __init__(self, d_model, nhead, dropout=0.0):\n        super(MaskedMultiheadAttention, self).__init__()\n        self.multihead_attn = nn.MultiheadAttention(d_model, nhead)\n        self.dropout = nn.Dropout(dropout)\n        \n    def generate_mask(self, seq_len):\n        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n        mask = mask == 0\n        mask = mask.float()\n        mask = mask.masked_fill(mask, float('-inf'))\n        return mask\n        \n    def forward(self, query, key, value):\n        \n        # Compute input sequence length\n        print(query.shape, type(query))\n        seq_len = query.shape[1]\n        \n        # Generate mask\n        mask = self.generate_mask(seq_len).to(device)\n        \n        # Transpose input for multi-head attention\n        query = query.permute(1, 0, 2)\n        key = key.permute(1, 0, 2)\n        value = value.permute(1, 0, 2)\n        \n        # Compute masked multi-head attention\n        output, _ = self.multihead_attn(query, key, value, attn_mask=mask)\n        \n        # Transpose output back to original shape\n        output = output.permute(1, 0, 2)\n        \n        # Apply dropout\n        output = self.dropout(output)\n        \n        \n        return output","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoder","metadata":{"editable":false}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, dModel, numHeads, dropout):\n        super(Encoder, self).__init__()\n        self.multiheadAttention = nn.MultiheadAttention(dModel, numHeads)\n        self.norm = nn.LayerNorm(dModel)\n        self.feedForward = nn.Sequential(\n            nn.Linear(dModel, 2048),\n            nn.ReLU(),\n            nn.Linear(2048, dModel)\n        )\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, source):\n        sourceAttentionOutput, _ = self.multiheadAttention(source, source, source)\n        source = source + self.dropout(sourceAttentionOutput)\n        source = self.norm(source)\n#         print(type(self.feedForward(source)))\n        feedForwardOutput = self.feedForward(source)\n        source = source + self.dropout(feedForwardOutput)\n        source = self.norm(source)\n        return source","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decoder","metadata":{"editable":false}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, dModel, numHeads, dropout):\n        super(Decoder, self).__init__()\n        self.multiheadAttention = nn.MultiheadAttention(dModel, numHeads)\n        self.maskedMultiheadAttention = MaskedMultiheadAttention(dModel, numHeads, dropout)\n        self.norm = nn.LayerNorm(dModel)\n        self.feedForward = nn.Sequential(\n            nn.Linear(dModel, 2048),\n            nn.ReLU(),\n            nn.Linear(2048, dModel)\n        )\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, source, target):\n        targetAttentionOutput = self.maskedMultiheadAttention(target, target, target)\n#         target = target + self.dropout(targetAttentionOutput)\n        target = self.norm(target)\n        \n        # Pad the source and target tensors along the sequence_length dimension to make them have the same length\n        maxLength = max(source.size(1), target.size(1))\n        source = torch.nn.functional.pad(source, (0, 0, 0, maxLength - source.size(1)))\n        target = torch.nn.functional.pad(target, (0, 0, 0, maxLength - target.size(1)))\n        \n        multiheadAttentionOutput = self.multiheadAttention(source, source, target)\n#         target = target + self.dropout(multiheadAttentionOutput)\n        target = self.norm(target)\n        feedForwardOutput = self.feedForward(source)\n        target = target + self.dropout(feedForwardOutput)\n        target = self.norm(target)\n        print(\"source:\", type(source))\n        print(\"target:\", type(target))\n        return source, target","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformer Layer","metadata":{"editable":false}},{"cell_type":"code","source":"class TransformerLayer(nn.Module):\n    def __init__(self, dModel, numHeads, dropout):\n        super(TransformerLayer, self).__init__()\n        self.encoder = Encoder(dModel, numHeads, dropout)\n        self.decoder = Decoder(dModel, numHeads, dropout)\n        \n    def forward(self, source, target):\n        source = self.encoder(source)\n        source, target = self.decoder(source, target)\n        return source, target","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformer","metadata":{"editable":false}},{"cell_type":"code","source":"# Define the Transformer model\nclass Transformer(nn.Module):\n    def __init__(self, vocabSize, dModel, numHeads, numLayers, dropout):\n        super(Transformer, self).__init__()\n        self.inputEmbeddings = nn.Embedding(vocabSize, dModel)\n        self.outputEmbeddings = nn.Embedding(vocabSize, dModel)\n        self.positionalEncoder = PositionalEncoder(dModel, Config.vocabSize)\n        self.transformerLayers = nn.ModuleList([TransformerLayer(dModel, numHeads, dropout) for _ in range(numLayers)])\n        self.fullyConnected = nn.Linear(dModel, vocabSize)\n        \n    def forward(self, source, target):\n\n        \n        source = self.inputEmbeddings(source)\n        source = self.positionalEncoder(source)\n        target = self.outputEmbeddings(target)\n        target = self.positionalEncoder(target)\n        for layer in self.transformerLayers:\n            source, target = layer(source, target)\n        output = self.fullyConnected(target)\n        return output\n","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Train**","metadata":{"editable":false}},{"cell_type":"code","source":"import gc","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training and validation functions\ndef train(model, iterator, optimizer, criterion, device):\n    model.train()\n    epoch_loss = 0\n    for en_data, bn_data in iterator:\n        en_data, bn_data = en_data.to(device), bn_data.to(device)\n        optimizer.zero_grad()\n        output = model(en_data, bn_data[:-1])\n        output = output.reshape(-1, output.shape[2])\n        bn_data = bn_data[1:].reshape(-1)\n        loss = criterion(output, bn_data)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(iterator)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, iterator, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for en_data, bn_data in iterator:\n            en_data, bn_data = en_data.to(device), bn_data.to(device)\n            output = model(en_data, bn_data[:-1])\n            output = output.reshape(-1, output.shape[2])\n            bn_data = bn_data[1:].reshape(-1)\n            loss = criterion(output, bn_data)\n            epoch_loss += loss.item()\n    return epoch_loss / len(iterator)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = Transformer(Config.vocabSize, Config.dModel, Config.numHeads, Config.numLayers, Config.dropout).to(device)\n# optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0, lr=Config.learningRate)\n# criterion = nn.CrossEntropyLoss()\n# for epoch in range(1, 100):\n#     print(\"Epoch\", epoch)\n#     train_loss = train_step(model, trainLoader, optimizer)\n#     print(f\"Train Loss for {epoch} : {train_loss}\")","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nbest_val_loss = float('inf')\nmodel = Transformer(Config.vocabSize, Config.dModel, Config.numHeads, Config.numLayers, Config.dropout).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), weight_decay=0, lr=Config.learningRate)\ncriterion = nn.CrossEntropyLoss()\nfor epoch in range(Config.epochs):\n    train_loss = train(model, trainLoader, optimizer, criterion, device)\n    val_loss = evaluate(model, validationLoader, criterion, device)\n    print(f'Epoch {epoch+1} Train Loss: {train_loss:.3f} Val Loss: {val_loss:.3f}')\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), 'best_model.pt')","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def train_step(model, trainLoader, optimizer):\n#     train_loss = 0\n    \n#     for batch, (target.to(device), source.to(device)) in enumerate(trainLoader):\n#         model.train()\n#         output = model(source, target)\n#         loss = loss_function(output, target)\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n#         train_loss += loss.item()\n        \n#         if batch % 50 == 0:\n#             print(f\"Train Loss for batch#{batch} : {loss.item()}\")\n        \n#         del source, target, output\n#         gc.collect()\n        \n        \n        \n    \n#     train_loss /= len(train_loss)\n#     return train_loss","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]}]}